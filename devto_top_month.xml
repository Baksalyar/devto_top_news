<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DEV.to Top Posts This Month</title>
    <link>https://dev.to/top/month</link>
    <description>Top DEV.to posts from the last 30 days.</description>
    <lastBuildDate>Wed, 11 Feb 2026 04:28:23 +0000</lastBuildDate>
    <item>
      <title>Stop Installing Libraries: 10 Browser APIs That Already Solve Your Problems</title>
      <link>https://dev.to/sylwia-lask/stop-installing-libraries-10-browser-apis-that-already-solve-your-problems-35bi</link>
      <guid isPermaLink="true">https://dev.to/sylwia-lask/stop-installing-libraries-10-browser-apis-that-already-solve-your-problems-35bi</guid>
      <pubDate>Wed, 04 Feb 2026 11:05:13 +0000</pubDate>
      <description><![CDATA[<p>The web platform is way more powerful than most developers realize ‚Äî and every year it quietly gains new superpowers.</p><p>Sometimes choosing a topic is harder than writing the article itself.</p><p>When I thought about what to write this week, only two types of ideas kept comming to mind: either potential bangers , or deep technical dives.üòÖ But I wanted something lighter. Still technical, still useful. But not a 3-day research rabbit hole.</p><p>And since I genuinely love exploring what the browser can do (and how far we can push it), I landed on a sneaky topic: underused Web APIs .</p><p>Some of these might be daily bread for you. But I‚Äôm pretty sure at least a few will make someone go ‚Äúwait, this exists?!‚Äù üòâ</p><p>And if you enjoy edge-tech topics and happen to be in Italy this April ‚Äî come to jsday.it , where I‚Äôll be speaking about WebGPU + WASM üôÇ</p><p>Alright, enough intro. Let‚Äôs start.</p><p>Here are 10 browser APIs that deserve way more love.</p><p>I have a love‚Äìhate relationship with this one.</p><p>For years, one of my favorite interview questions to ask candidates was:</p><p>‚ÄúHow do you copy an object?‚Äù</p><p>‚ÄúHow do you copy an object?‚Äù</p><p>You could learn so much from the answer:</p><p>Do they understand references?</p><p>Do they know Object.assign , spread, JSON tricks?</p><p>Do they mention libraries?</p><p>Do they panic? üòÑ</p><p>Now?</p><p>Boom. Perfect deep copy.</p><p>Part of me is happy. Part of me misses that interview question already.</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>The web platform is way more powerful than most developers realize ‚Äî and every year it quietly gains new superpowers.</p><p>Sometimes choosing a topic is harder than writing the article itself.</p><p>When I thought about what to write this week, only two types of ideas kept comming to mind: either potential bangers , or deep technical dives.üòÖ But I wanted something lighter. Still technical, still useful. But not a 3-day research rabbit hole.</p><p>And since I genuinely love exploring what the browser can do (and how far we can push it), I landed on a sneaky topic: underused Web APIs .</p><p>Some of these might be daily bread for you. But I‚Äôm pretty sure at least a few will make someone go ‚Äúwait, this exists?!‚Äù üòâ</p><p>And if you enjoy edge-tech topics and happen to be in Italy this April ‚Äî come to jsday.it , where I‚Äôll be speaking about WebGPU + WASM üôÇ</p><p>Alright, enough intro. Let‚Äôs start.</p><p>Here are 10 browser APIs that deserve way more love.</p><p>I have a love‚Äìhate relationship with this one.</p><p>For years, one of my favorite interview questions to ask candidates was:</p><p>‚ÄúHow do you copy an object?‚Äù</p><p>‚ÄúHow do you copy an object?‚Äù</p><p>You could learn so much from the answer:</p><p>Do they understand references?</p><p>Do they know Object.assign , spread, JSON tricks?</p><p>Do they mention libraries?</p><p>Do they panic? üòÑ</p><p>Now?</p><p>Boom. Perfect deep copy.</p><p>Part of me is happy. Part of me misses that interview question already.</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>We&#x27;re Creating a Knowledge Collapse and No One&#x27;s Talking About It</title>
      <link>https://dev.to/dannwaneri/were-creating-a-knowledge-collapse-and-no-ones-talking-about-it-226d</link>
      <guid isPermaLink="true">https://dev.to/dannwaneri/were-creating-a-knowledge-collapse-and-no-ones-talking-about-it-226d</guid>
      <pubDate>Tue, 27 Jan 2026 01:59:58 +0000</pubDate>
      <description><![CDATA[<p>&quot;Hostile experts created the dataset for patient machines.&quot;</p><p>That line, from a comment by Vinicius Fagundes on my last article, won&#x27;t leave my head.</p><p>Stack Overflow&#x27;s traffic collapsed 78% in two years. Everyone&#x27;s celebrating that AI finally killed the gatekeepers. But here&#x27;s what we&#x27;re not asking:</p><p>If we all stop contributing to public knowledge bases, what does the next generation of AI even train on?</p><p>We might be optimizing ourselves into a knowledge dead-end.</p><p>Stack Overflow went from 200,000 questions per month at its peak to under 50,000 by late 2025. That&#x27;s not a dip. That&#x27;s a collapse.</p><p>Meanwhile, 84% of developers now use AI tools in their workflow, up from 76% just a year ago. Among professional developers, 51% use AI daily.</p><p>The shift is real. The speed is undeniable. But here&#x27;s the uncomfortable part: 52% of ChatGPT&#x27;s answers to Stack Overflow questions are incorrect.</p><p>The irony is brutal:</p><p>AI trained on Stack Overflow</p><p>Developers replaced Stack Overflow with AI</p><p>Stack Overflow dies from lack of new content</p><p>Future AI has... what, exactly?</p><p>Here&#x27;s something nobody&#x27;s complaining about loudly enough: Wikipedia sometimes doesn&#x27;t even appear on the first page of Google results anymore.</p><p>Let that sink in. The largest collaborative knowledge project in human history - free, community-curated, constantly updated, with 60+ million articles - is getting buried by AI-generated summaries and SEO-optimized content farms.</p><p>Google would rather show you an AI-generated answer panel (trained on Wikipedia) than send you to Wikipedia itself. The thing that created the knowledge gets pushed down. The thing that consumed the knowledge gets prioritized.</p><p>This is the loop closing in real-time:</p><p>Humans build Wikipedia collaboratively</p><p>AI trains on Wikipedia</p><p>Google prioritizes AI summaries over Wikipedia</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>&quot;Hostile experts created the dataset for patient machines.&quot;</p><p>That line, from a comment by Vinicius Fagundes on my last article, won&#x27;t leave my head.</p><p>Stack Overflow&#x27;s traffic collapsed 78% in two years. Everyone&#x27;s celebrating that AI finally killed the gatekeepers. But here&#x27;s what we&#x27;re not asking:</p><p>If we all stop contributing to public knowledge bases, what does the next generation of AI even train on?</p><p>We might be optimizing ourselves into a knowledge dead-end.</p><p>Stack Overflow went from 200,000 questions per month at its peak to under 50,000 by late 2025. That&#x27;s not a dip. That&#x27;s a collapse.</p><p>Meanwhile, 84% of developers now use AI tools in their workflow, up from 76% just a year ago. Among professional developers, 51% use AI daily.</p><p>The shift is real. The speed is undeniable. But here&#x27;s the uncomfortable part: 52% of ChatGPT&#x27;s answers to Stack Overflow questions are incorrect.</p><p>The irony is brutal:</p><p>AI trained on Stack Overflow</p><p>Developers replaced Stack Overflow with AI</p><p>Stack Overflow dies from lack of new content</p><p>Future AI has... what, exactly?</p><p>Here&#x27;s something nobody&#x27;s complaining about loudly enough: Wikipedia sometimes doesn&#x27;t even appear on the first page of Google results anymore.</p><p>Let that sink in. The largest collaborative knowledge project in human history - free, community-curated, constantly updated, with 60+ million articles - is getting buried by AI-generated summaries and SEO-optimized content farms.</p><p>Google would rather show you an AI-generated answer panel (trained on Wikipedia) than send you to Wikipedia itself. The thing that created the knowledge gets pushed down. The thing that consumed the knowledge gets prioritized.</p><p>This is the loop closing in real-time:</p><p>Humans build Wikipedia collaboratively</p><p>AI trains on Wikipedia</p><p>Google prioritizes AI summaries over Wikipedia</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash üí∏</title>
      <link>https://dev.to/devteam/join-the-github-copilot-cli-challenge-win-github-universe-tickets-copilot-pro-subscriptions-and-50af</link>
      <guid isPermaLink="true">https://dev.to/devteam/join-the-github-copilot-cli-challenge-win-github-universe-tickets-copilot-pro-subscriptions-and-50af</guid>
      <pubDate>Thu, 22 Jan 2026 14:05:49 +0000</pubDate>
      <description><![CDATA[<p>We&#x27;re excited to announce our newest challenge with GitHub !</p><p>Running through February 15 , the GitHub Copilot CLI Challenge invites you to experience the power of GitHub Copilot directly in your terminal.</p><p>GitHub Copilot CLI brings AI-powered coding assistance to your command line, enabling you to build, debug, and understand code through natural language conversations.</p><p>Whether you&#x27;re building productivity tools, fun experiments, or solving everyday problems, this challenge is the perfect opportunity to explore what&#x27;s possible when AI meets the command line.</p><p>We have some really great prizes for this challenge, and there are many opportunities to win! Read on to learn more.</p><p>Your mandate is to build an application using GitHub Copilot CLI. What should you build? That&#x27;s entirely up to you! Here are some ideas to get you started:</p><p>Productivity boosters: Tools that make your daily workflow smoother</p><p>Fun experiments: That silly idea you&#x27;ve always wanted an excuse to build</p><p>Problem solvers: Solutions to common pain points you or others face</p><p>Creative utilities: Unique tools that showcase what Copilot CLI can do</p><p>The most important aspect? Show us how GitHub Copilot CLI enhances your development process and helps you build something awesome.</p><p>Three Winners will each receive:</p><p>$1,000 USD</p><p>Ticket to GitHub Universe 2026 (October 28-29)</p><p>Exclusive DEV Badge</p><p>25 Runner-Ups will each receive:</p><p>1-year GitHub Copilot Pro+ subscription</p><p>Exclusive DEV Badge</p><p>All Participants with a valid submission will receive a completion badge on their DEV profile.</p><p>In order to participate, you&#x27;ll need to use GitHub Copilot CLI in your project and publish a post using the submission template below.</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>We&#x27;re excited to announce our newest challenge with GitHub !</p><p>Running through February 15 , the GitHub Copilot CLI Challenge invites you to experience the power of GitHub Copilot directly in your terminal.</p><p>GitHub Copilot CLI brings AI-powered coding assistance to your command line, enabling you to build, debug, and understand code through natural language conversations.</p><p>Whether you&#x27;re building productivity tools, fun experiments, or solving everyday problems, this challenge is the perfect opportunity to explore what&#x27;s possible when AI meets the command line.</p><p>We have some really great prizes for this challenge, and there are many opportunities to win! Read on to learn more.</p><p>Your mandate is to build an application using GitHub Copilot CLI. What should you build? That&#x27;s entirely up to you! Here are some ideas to get you started:</p><p>Productivity boosters: Tools that make your daily workflow smoother</p><p>Fun experiments: That silly idea you&#x27;ve always wanted an excuse to build</p><p>Problem solvers: Solutions to common pain points you or others face</p><p>Creative utilities: Unique tools that showcase what Copilot CLI can do</p><p>The most important aspect? Show us how GitHub Copilot CLI enhances your development process and helps you build something awesome.</p><p>Three Winners will each receive:</p><p>$1,000 USD</p><p>Ticket to GitHub Universe 2026 (October 28-29)</p><p>Exclusive DEV Badge</p><p>25 Runner-Ups will each receive:</p><p>1-year GitHub Copilot Pro+ subscription</p><p>Exclusive DEV Badge</p><p>All Participants with a valid submission will receive a completion badge on their DEV profile.</p><p>In order to participate, you&#x27;ll need to use GitHub Copilot CLI in your project and publish a post using the submission template below.</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Fighting Spam at Scale: How We Use Gemini to Protect the DEV Community</title>
      <link>https://dev.to/devteam/fighting-spam-at-scale-how-we-use-gemini-to-protect-the-dev-community-277j</link>
      <guid isPermaLink="true">https://dev.to/devteam/fighting-spam-at-scale-how-we-use-gemini-to-protect-the-dev-community-277j</guid>
      <pubDate>Thu, 22 Jan 2026 15:17:21 +0000</pubDate>
      <description><![CDATA[<p>Eliminating spam has been a massive priority for us at DEV (and the wider Forem ecosystem). If you‚Äôve been with us for a while, you recall that this has been a significant problem in the past. While no platform can claim to be 100% spam-free, the situation is much improved today.</p><p>Our primary goal with these recent updates is simple: get super low-quality content off the platform before a human moderator ever has to deal with it.</p><p>Moderator burnout is real. By automating the removal of the &quot;obvious&quot; junk, we allow our mods to focus on nuanced community interactions rather than deleting hundreds of crypto-scam posts.</p><p>We don‚Äôt rely on just one tool. We use a combination of upstream algorithmic detection and &quot;call-outs&quot; to Gemini for independent analysis.</p><p>Algorithmic Upstream Action: If we detect a clear trend‚Äîfor example, a massive burst of posts linking to a specific spam website‚Äîwe take action upstream. We prefer to handle these efficiently without needing to query an LLM for every single instance.</p><p>Gemini Analysis: For individual posts that require judgment, we send a custom prompt to Gemini 3. We try to err on the side of &quot;no false positives,&quot; but when the AI detects clear indicators of spam or harmful content, it applies a label that triggers automated workflows.</p><p>To give you a better picture of how this works technically, let&#x27;s look at our ContentModerationLabeler service. This Ruby class is responsible for building the context and asking Gemini to categorize the post.</p><p>We hone these custom prompts over time to ensure accuracy. Here is how we define the assessment criteria within the prompt. We tell Gemini exactly what we are looking for, distinguishing between &quot;Safety,&quot; &quot;Quality,&quot; and &quot;Spam&quot;:</p><p>One key to our success is that we don&#x27;t just send Gemini the text of the article. We also build a User Context .</p><p>A post that looks &quot;okay&quot; might actually be spam if it comes from a brand-new account with zero history. Conversely, a trusted member with badges and years of history gets the benefit of the doubt. We feed these metrics into the prompt so Gemini has the full picture:</p><p>View the ContentModerationLabeler on GitHub</p><p>One interesting observation from our data is regarding the volume of spam. Ironically, the cumulative amount of labeled spam peaked right before we fully integrated these new systems. Spam peak was summer of 2025.</p><p>This happens because deterrence works. As soon as bad actors realize their automated scripts are hitting a wall and their posts are being nuked immediately by our automated systems, they stop wasting resources on our platform. The high wall of entry leads to fewer attempts over time.</p><p>This system will continue to evolve. We are constantly tweaking our prompts and our upstream algorithms to adapt to new spam tactics.</p><p>While there are several services that handle different types of spam across the platform, you can view the full source code for this specific approach in our open-source repository:</p><p>For Empowering Community</p><p>Welcome to the Forem codebase, the platform that powers dev.to . We are so excited to have you. With your help, we can
build out Forem‚Äôs usability, scalability, and stability to better serve our
communities.</p><p>Forem is open source software for building communities. Communities for your
peers, customers, fanbases, families, friends, and any other time and space
where people need to come together to be part of a collective See our announcement post for a high-level overview of what Forem is.</p><p>dev.to (or just DEV) is hosted by Forem. It is a community of
software developers who write articles, take part in discussions, and build
their professional profiles. We value supportive and constructive dialogue in
the pursuit of great code and career growth for all members. The ecosystem spans
from beginner to advanced developers, and all are welcome to find their place‚Ä¶</p><p>Happy coding ‚ù§Ô∏è</p>]]></description>
      <content:encoded><![CDATA[<p>Eliminating spam has been a massive priority for us at DEV (and the wider Forem ecosystem). If you‚Äôve been with us for a while, you recall that this has been a significant problem in the past. While no platform can claim to be 100% spam-free, the situation is much improved today.</p><p>Our primary goal with these recent updates is simple: get super low-quality content off the platform before a human moderator ever has to deal with it.</p><p>Moderator burnout is real. By automating the removal of the &quot;obvious&quot; junk, we allow our mods to focus on nuanced community interactions rather than deleting hundreds of crypto-scam posts.</p><p>We don‚Äôt rely on just one tool. We use a combination of upstream algorithmic detection and &quot;call-outs&quot; to Gemini for independent analysis.</p><p>Algorithmic Upstream Action: If we detect a clear trend‚Äîfor example, a massive burst of posts linking to a specific spam website‚Äîwe take action upstream. We prefer to handle these efficiently without needing to query an LLM for every single instance.</p><p>Gemini Analysis: For individual posts that require judgment, we send a custom prompt to Gemini 3. We try to err on the side of &quot;no false positives,&quot; but when the AI detects clear indicators of spam or harmful content, it applies a label that triggers automated workflows.</p><p>To give you a better picture of how this works technically, let&#x27;s look at our ContentModerationLabeler service. This Ruby class is responsible for building the context and asking Gemini to categorize the post.</p><p>We hone these custom prompts over time to ensure accuracy. Here is how we define the assessment criteria within the prompt. We tell Gemini exactly what we are looking for, distinguishing between &quot;Safety,&quot; &quot;Quality,&quot; and &quot;Spam&quot;:</p><p>One key to our success is that we don&#x27;t just send Gemini the text of the article. We also build a User Context .</p><p>A post that looks &quot;okay&quot; might actually be spam if it comes from a brand-new account with zero history. Conversely, a trusted member with badges and years of history gets the benefit of the doubt. We feed these metrics into the prompt so Gemini has the full picture:</p><p>View the ContentModerationLabeler on GitHub</p><p>One interesting observation from our data is regarding the volume of spam. Ironically, the cumulative amount of labeled spam peaked right before we fully integrated these new systems. Spam peak was summer of 2025.</p><p>This happens because deterrence works. As soon as bad actors realize their automated scripts are hitting a wall and their posts are being nuked immediately by our automated systems, they stop wasting resources on our platform. The high wall of entry leads to fewer attempts over time.</p><p>This system will continue to evolve. We are constantly tweaking our prompts and our upstream algorithms to adapt to new spam tactics.</p><p>While there are several services that handle different types of spam across the platform, you can view the full source code for this specific approach in our open-source repository:</p><p>For Empowering Community</p><p>Welcome to the Forem codebase, the platform that powers dev.to . We are so excited to have you. With your help, we can
build out Forem‚Äôs usability, scalability, and stability to better serve our
communities.</p><p>Forem is open source software for building communities. Communities for your
peers, customers, fanbases, families, friends, and any other time and space
where people need to come together to be part of a collective See our announcement post for a high-level overview of what Forem is.</p><p>dev.to (or just DEV) is hosted by Forem. It is a community of
software developers who write articles, take part in discussions, and build
their professional profiles. We value supportive and constructive dialogue in
the pursuit of great code and career growth for all members. The ecosystem spans
from beginner to advanced developers, and all are welcome to find their place‚Ä¶</p><p>Happy coding ‚ù§Ô∏è</p>]]></content:encoded>
    </item>
    <item>
      <title>Is Learning CSS a Waste of Time in 2026?</title>
      <link>https://dev.to/sylwia-lask/is-learning-css-a-waste-of-time-in-2026-nj3</link>
      <guid isPermaLink="true">https://dev.to/sylwia-lask/is-learning-css-a-waste-of-time-in-2026-nj3</guid>
      <pubDate>Thu, 29 Jan 2026 11:07:18 +0000</pubDate>
      <description><![CDATA[<p>With modern frameworks, component libraries, and utility-first CSS, it‚Äôs a fair question.</p><p>Most frontend developers today rarely write ‚Äúreal‚Äù CSS. Layouts come prebuilt. Responsiveness is handled for us. Accessibility is supposed to be baked in. If something needs styling, we tweak a variable, add a utility class, or override a component token.</p><p>So‚Ä¶ why spend time learning CSS at all?</p><p>For a long time, I thought the same. Until accessibility forced me back into it.</p><p>Recently, I had a task that sounded quite innocent: take an old component and bring it up to modern WCAG accessibility standards .</p><p>You know ‚Äî better accessibility, higher contrast, proper focus states. Not a nice-to-have . A hard requirement, because I treat accessibility very serious.</p><p>In practice, it meant a lot of CSS work . The container had to be heavily reworked, but the visual design had to stay exactly the same.</p><p>And wow‚Ä¶ I struggled. A lot. üòÖ</p><p>At some point I caught myself thinking:</p><p>CSS might actually be the hardest part of frontend development. More complicated than JavaScript.</p><p>CSS might actually be the hardest part of frontend development. More complicated than JavaScript.</p><p>(Okay, maybe it didn‚Äôt help that the previous developer clearly didn‚Äôt understand CSS either üò¨)</p><p>What makes this funny is that I used to be really good at CSS .</p><p>Box model? Easy. Layout tricks? Daily bread. I could even center an element both vertically and horizontally ‚Äî without Googling üòÑ</p><p>A long time ago, I even made some extra money building WordPress websites. Technically simple stuff, but clients paid me because the pages looked good . That was the value.</p><p>So‚Ä¶ what happened?</p><p>This recent task was a harsh reminder.</p><p>The real problems weren‚Äôt colors or fonts ‚Äî they were things like:</p><p>focus outlines breaking the layout</p><p>keyboard navigation suddenly revealing broken DOM order</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>With modern frameworks, component libraries, and utility-first CSS, it‚Äôs a fair question.</p><p>Most frontend developers today rarely write ‚Äúreal‚Äù CSS. Layouts come prebuilt. Responsiveness is handled for us. Accessibility is supposed to be baked in. If something needs styling, we tweak a variable, add a utility class, or override a component token.</p><p>So‚Ä¶ why spend time learning CSS at all?</p><p>For a long time, I thought the same. Until accessibility forced me back into it.</p><p>Recently, I had a task that sounded quite innocent: take an old component and bring it up to modern WCAG accessibility standards .</p><p>You know ‚Äî better accessibility, higher contrast, proper focus states. Not a nice-to-have . A hard requirement, because I treat accessibility very serious.</p><p>In practice, it meant a lot of CSS work . The container had to be heavily reworked, but the visual design had to stay exactly the same.</p><p>And wow‚Ä¶ I struggled. A lot. üòÖ</p><p>At some point I caught myself thinking:</p><p>CSS might actually be the hardest part of frontend development. More complicated than JavaScript.</p><p>CSS might actually be the hardest part of frontend development. More complicated than JavaScript.</p><p>(Okay, maybe it didn‚Äôt help that the previous developer clearly didn‚Äôt understand CSS either üò¨)</p><p>What makes this funny is that I used to be really good at CSS .</p><p>Box model? Easy. Layout tricks? Daily bread. I could even center an element both vertically and horizontally ‚Äî without Googling üòÑ</p><p>A long time ago, I even made some extra money building WordPress websites. Technically simple stuff, but clients paid me because the pages looked good . That was the value.</p><p>So‚Ä¶ what happened?</p><p>This recent task was a harsh reminder.</p><p>The real problems weren‚Äôt colors or fonts ‚Äî they were things like:</p><p>focus outlines breaking the layout</p><p>keyboard navigation suddenly revealing broken DOM order</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Your GitHub Contribution Graph Means Absolutely Nothing - And Here‚Äôs Why</title>
      <link>https://dev.to/sylwia-lask/your-github-contribution-graph-means-absolutely-nothing-and-heres-why-2kjc</link>
      <guid isPermaLink="true">https://dev.to/sylwia-lask/your-github-contribution-graph-means-absolutely-nothing-and-heres-why-2kjc</guid>
      <pubDate>Tue, 13 Jan 2026 11:42:28 +0000</pubDate>
      <description><![CDATA[<p>If your GitHub contribution graph disappeared tomorrow, would that make you a worse developer?</p><p>For years, we‚Äôve been trained ‚Äî consciously or not ‚Äî to treat green squares as a proxy for competence, discipline, or even passion.</p><p>TL;DR: A GitHub contribution graph measures neither productivity, nor skill, nor engagement as a developer.</p><p>Let me start with two very short stories that inspired me to write this article.</p><p>This discussion was inspired by an article I recently read on DEV.</p><p>The author described how he created an app that automatically commits his code. According to him, he programs a lot, but often simply forgets to commit and push his changes ‚Äî which makes his GitHub contribution graph look‚Ä¶ poor.</p><p>And while I absolutely respect the curiosity, creativity, and the act of turning an idea into a working project, one thought immediately crossed my mind:</p><p>Who on earth evaluates developers based on the number of their commits?</p><p>That makes very little sense.</p><p>Many people in the comments agreed, but some shared stories from job interviews where managers actually asked candidates why their GitHub activity was so low. Even if the answer made perfect sense (for example: most of their work lives in private company repositories) and the interview continued normally, there was still that unpleasant feeling ‚Äî the candidate was pushed into a defensive position for no good reason.</p><p>Personally, I‚Äôve participated in many recruitment processes and was asked about my GitHub exactly once. But maybe I‚Äôm just lucky?</p><p>A few days earlier, a friend from my previous job shared a screenshot of someone‚Äôs contribution graph. I‚Äôve modified it here to protect privacy, but it looked roughly like this (The AI stubbornly paints 8 days a week instead of 7 ‚Äî let&#x27;s keep it that way üôÉ):</p><p>Impressive? Maybe. Terrifying? Also maybe.</p><p>My friend ‚Äî a very empathetic person ‚Äî didn‚Äôt feel admiration at all. Instead, he felt concern.</p><p>Where is the work-life balance? When does this person rest? How does this human being even function?</p><p>The mystery was solved pretty quickly. The graph most likely looked like this because the user had a job that ran a daily database backup .</p><p>For the record: this person actually was very active on GitHub and contributed to many open-source projects ‚Äî just‚Ä¶ not that much.</p><p>And this is where we get to the core of the problem.</p><p>By design, it never should have been. And it doesn‚Äôt hold up to even basic common sense.</p><p>And yet, somehow, we still look at it and think:</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>If your GitHub contribution graph disappeared tomorrow, would that make you a worse developer?</p><p>For years, we‚Äôve been trained ‚Äî consciously or not ‚Äî to treat green squares as a proxy for competence, discipline, or even passion.</p><p>TL;DR: A GitHub contribution graph measures neither productivity, nor skill, nor engagement as a developer.</p><p>Let me start with two very short stories that inspired me to write this article.</p><p>This discussion was inspired by an article I recently read on DEV.</p><p>The author described how he created an app that automatically commits his code. According to him, he programs a lot, but often simply forgets to commit and push his changes ‚Äî which makes his GitHub contribution graph look‚Ä¶ poor.</p><p>And while I absolutely respect the curiosity, creativity, and the act of turning an idea into a working project, one thought immediately crossed my mind:</p><p>Who on earth evaluates developers based on the number of their commits?</p><p>That makes very little sense.</p><p>Many people in the comments agreed, but some shared stories from job interviews where managers actually asked candidates why their GitHub activity was so low. Even if the answer made perfect sense (for example: most of their work lives in private company repositories) and the interview continued normally, there was still that unpleasant feeling ‚Äî the candidate was pushed into a defensive position for no good reason.</p><p>Personally, I‚Äôve participated in many recruitment processes and was asked about my GitHub exactly once. But maybe I‚Äôm just lucky?</p><p>A few days earlier, a friend from my previous job shared a screenshot of someone‚Äôs contribution graph. I‚Äôve modified it here to protect privacy, but it looked roughly like this (The AI stubbornly paints 8 days a week instead of 7 ‚Äî let&#x27;s keep it that way üôÉ):</p><p>Impressive? Maybe. Terrifying? Also maybe.</p><p>My friend ‚Äî a very empathetic person ‚Äî didn‚Äôt feel admiration at all. Instead, he felt concern.</p><p>Where is the work-life balance? When does this person rest? How does this human being even function?</p><p>The mystery was solved pretty quickly. The graph most likely looked like this because the user had a job that ran a daily database backup .</p><p>For the record: this person actually was very active on GitHub and contributed to many open-source projects ‚Äî just‚Ä¶ not that much.</p><p>And this is where we get to the core of the problem.</p><p>By design, it never should have been. And it doesn‚Äôt hold up to even basic common sense.</p><p>And yet, somehow, we still look at it and think:</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>The &#x27;Senior Developer&#x27; is now the new &#x27;Entry Level&#x27;</title>
      <link>https://dev.to/maame-codes/the-senior-developer-is-now-the-new-entry-level-49d1</link>
      <guid isPermaLink="true">https://dev.to/maame-codes/the-senior-developer-is-now-the-new-entry-level-49d1</guid>
      <pubDate>Wed, 14 Jan 2026 17:48:39 +0000</pubDate>
      <description><![CDATA[<p>I do think most of us can attest to the fact that, entry level roles are not &#x27;entry&#x27; anymore, I do see alot of tech jobs on sites with &#x27;2 or more years of experience&#x27; (how are we supposed to get that experience if no one wants to hire entry level applicants?!)</p><p>I check my email like checking the time, just to see if I get a &#x27;congratulations..&#x27; message, or an opportunity that would help pivot my career somehow? It was a saturday, I didn&#x27;t sleep much the day before so I woke up around mid afternoon. First thing I usually do is to check my mail (even before other social media apps). I saw a &#x27;congratulations, you have been shortlisted for the role...&#x27; . I was so excited! Till I went for the interview and did not get the job...</p><p>Between lectures on compiler theory and trying to master DevOps, I just wanted a part-time junior gig, something to pay the rent and finally get some &quot;real-world&quot; experience on my CV.</p><p>I found a startup nearby hiring for a &quot;Junior Web Developer.&quot; The job description was standard 2024 stuff: React, Node, basic Git. I‚Äôve built a dozen projects like that. I walked in thinking I was overqualified.</p><p>I walked out realizing the job I was looking for doesn&#x27;t exist anymore.</p><p>The Interview that Broke Me</p><p>The interviewer didn&#x27;t ask to see my GitHub. He didn&#x27;t ask me to whiteboard an algorithm. He just pointed at a screen with 2,000 lines of fresh, AI-generated TypeScript.</p><p>&quot;I just let go of our last junior,&quot; he said, and my stomach dropped. &quot;He was great at writing code, but I don&#x27;t need a writer anymore. I have an agent for that. I need a Forensic Auditor.&quot;</p><p>He set a timer for 20 minutes. &quot;The agent says this payment gateway refactor is &#x27;Successful.&#x27; My logs say otherwise. Tell me why the machine is lying to me.&quot;</p><p>I sat there staring at the most &quot;perfect&quot; code I‚Äôd ever seen. No typos. Perfect indentation. But I froze. I spent my labs at Uni learning how to create loops, not how to find a microscopic logic flaw in a &quot;perfect&quot; hallucination.</p><p>I didn&#x27;t find the bug. The timer hit zero. I didn&#x27;t get the job.</p><p>Why the &quot;Junior&quot; Label is a Lie in 2026</p><p>Walking back to the Mile End station, it hit me: The &quot;Junior Developer&quot; hasn&#x27;t just moved, it‚Äôs been deleted .</p><p>In 2022, your value was being a &quot;coder.&quot; In 2026, your value is being a Senior-level Filter.</p><p>The industry has lost its patience for the &quot;ramp-up&quot; period. Companies aren&#x27;t hiring for potential anymore; they‚Äôre hiring for control. They want people who can act like a Lead on Day 1 because the AI is already handling the &quot;Junior&quot; work (boilerplate, unit tests, basic CRUD) for free.</p><p>The Computer Lab vs. The Real World</p><p>At Uni, we‚Äôre still arguing over semicolons. In the real world, the Lead Architect is managing a fleet of 10 AI agents while they sleep.</p><p>The &quot;traditional&quot; student roadmap is a total trap. If your resume says you &quot;know Python and Java,&quot; you&#x27;re competing with a calculator. If you‚Äôre still grinding LeetCode Easy, you‚Äôre training for a race that ended two years ago.</p><p>To actually get hired in 2026, you have to leapfrog the &quot;Junior&quot; phase entirely. Entry-level now means:</p><p>System Forensics: Can you debug a &quot;perfect&quot; system you didn&#x27;t write?</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>I do think most of us can attest to the fact that, entry level roles are not &#x27;entry&#x27; anymore, I do see alot of tech jobs on sites with &#x27;2 or more years of experience&#x27; (how are we supposed to get that experience if no one wants to hire entry level applicants?!)</p><p>I check my email like checking the time, just to see if I get a &#x27;congratulations..&#x27; message, or an opportunity that would help pivot my career somehow? It was a saturday, I didn&#x27;t sleep much the day before so I woke up around mid afternoon. First thing I usually do is to check my mail (even before other social media apps). I saw a &#x27;congratulations, you have been shortlisted for the role...&#x27; . I was so excited! Till I went for the interview and did not get the job...</p><p>Between lectures on compiler theory and trying to master DevOps, I just wanted a part-time junior gig, something to pay the rent and finally get some &quot;real-world&quot; experience on my CV.</p><p>I found a startup nearby hiring for a &quot;Junior Web Developer.&quot; The job description was standard 2024 stuff: React, Node, basic Git. I‚Äôve built a dozen projects like that. I walked in thinking I was overqualified.</p><p>I walked out realizing the job I was looking for doesn&#x27;t exist anymore.</p><p>The Interview that Broke Me</p><p>The interviewer didn&#x27;t ask to see my GitHub. He didn&#x27;t ask me to whiteboard an algorithm. He just pointed at a screen with 2,000 lines of fresh, AI-generated TypeScript.</p><p>&quot;I just let go of our last junior,&quot; he said, and my stomach dropped. &quot;He was great at writing code, but I don&#x27;t need a writer anymore. I have an agent for that. I need a Forensic Auditor.&quot;</p><p>He set a timer for 20 minutes. &quot;The agent says this payment gateway refactor is &#x27;Successful.&#x27; My logs say otherwise. Tell me why the machine is lying to me.&quot;</p><p>I sat there staring at the most &quot;perfect&quot; code I‚Äôd ever seen. No typos. Perfect indentation. But I froze. I spent my labs at Uni learning how to create loops, not how to find a microscopic logic flaw in a &quot;perfect&quot; hallucination.</p><p>I didn&#x27;t find the bug. The timer hit zero. I didn&#x27;t get the job.</p><p>Why the &quot;Junior&quot; Label is a Lie in 2026</p><p>Walking back to the Mile End station, it hit me: The &quot;Junior Developer&quot; hasn&#x27;t just moved, it‚Äôs been deleted .</p><p>In 2022, your value was being a &quot;coder.&quot; In 2026, your value is being a Senior-level Filter.</p><p>The industry has lost its patience for the &quot;ramp-up&quot; period. Companies aren&#x27;t hiring for potential anymore; they‚Äôre hiring for control. They want people who can act like a Lead on Day 1 because the AI is already handling the &quot;Junior&quot; work (boilerplate, unit tests, basic CRUD) for free.</p><p>The Computer Lab vs. The Real World</p><p>At Uni, we‚Äôre still arguing over semicolons. In the real world, the Lead Architect is managing a fleet of 10 AI agents while they sleep.</p><p>The &quot;traditional&quot; student roadmap is a total trap. If your resume says you &quot;know Python and Java,&quot; you&#x27;re competing with a calculator. If you‚Äôre still grinding LeetCode Easy, you‚Äôre training for a race that ended two years ago.</p><p>To actually get hired in 2026, you have to leapfrog the &quot;Junior&quot; phase entirely. Entry-level now means:</p><p>System Forensics: Can you debug a &quot;perfect&quot; system you didn&#x27;t write?</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>How dev.to became my comfortable corner of the internet (and my New Year resolution)</title>
      <link>https://dev.to/ujja/how-devto-became-my-comfortable-corner-of-the-internet-and-my-new-year-resolution-54h8</link>
      <guid isPermaLink="true">https://dev.to/ujja/how-devto-became-my-comfortable-corner-of-the-internet-and-my-new-year-resolution-54h8</guid>
      <pubDate>Mon, 09 Feb 2026 22:40:35 +0000</pubDate>
      <description><![CDATA[<p>It has been a little over 10 years since I deleted my Facebook account.</p><p>No long post. No explanation. I just logged out and never went back.</p><p>I never joined Instagram either. Or Twitter. Or Snapchat. Or any other social networking platform. That always surprises people, but honestly, it never felt like something I needed.</p><p>And after all these years, I can confidently say this I do not miss it at all.</p><p>Back then, Facebook just felt loud. Everyone was sharing everything. Opinions, achievements, arguments, perfectly happy lives. I would scroll and somehow feel worse than when I started.</p><p>Deleting it gave me something I did not even know I was craving. Quiet.</p><p>No constant comparison. No endless updates from people I barely spoke to. No pressure to react, like, comment, or keep up.</p><p>Once that noise was gone, I never felt the urge to go back.</p><p>I do have LinkedIn, but my usage is very limited.</p><p>Mostly because even there, comparison sneaks in. You see people announcing promotions, new roles, startup wins, big milestones. And even if you are happy for them, a tiny part of your brain goes Should I be doing more? Am I behind?</p><p>That jealousy is human. I feel it too. So I keep my time there minimal and intentional.</p><p>I enjoy technical writing. I always have.</p><p>For a long time, I would write technical articles and share them on LinkedIn. That was the only place I knew. Around that time (close to six years ago), a friend of mine suggested I try dev.to instead.</p><p>Their reasoning was simple If you enjoy tech, share it where it helps the community Let others learn from your experience and you will learn from theirs too</p><p>That idea stuck with me.</p><p>dev.to feels like a completely different space.</p><p>It does not feel like a highlight reel. It feels like a shared journey.</p><p>People celebrate each other when things work. And when things break, people are genuinely heartbroken together. Builds fail, ideas flop, bugs refuse to die and everyone learns from it.</p><p>There is honesty here. You see what worked and what absolutely did not. And that makes success feel real, not staged.</p><p>It feels less like performing and more like sharing.</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>It has been a little over 10 years since I deleted my Facebook account.</p><p>No long post. No explanation. I just logged out and never went back.</p><p>I never joined Instagram either. Or Twitter. Or Snapchat. Or any other social networking platform. That always surprises people, but honestly, it never felt like something I needed.</p><p>And after all these years, I can confidently say this I do not miss it at all.</p><p>Back then, Facebook just felt loud. Everyone was sharing everything. Opinions, achievements, arguments, perfectly happy lives. I would scroll and somehow feel worse than when I started.</p><p>Deleting it gave me something I did not even know I was craving. Quiet.</p><p>No constant comparison. No endless updates from people I barely spoke to. No pressure to react, like, comment, or keep up.</p><p>Once that noise was gone, I never felt the urge to go back.</p><p>I do have LinkedIn, but my usage is very limited.</p><p>Mostly because even there, comparison sneaks in. You see people announcing promotions, new roles, startup wins, big milestones. And even if you are happy for them, a tiny part of your brain goes Should I be doing more? Am I behind?</p><p>That jealousy is human. I feel it too. So I keep my time there minimal and intentional.</p><p>I enjoy technical writing. I always have.</p><p>For a long time, I would write technical articles and share them on LinkedIn. That was the only place I knew. Around that time (close to six years ago), a friend of mine suggested I try dev.to instead.</p><p>Their reasoning was simple If you enjoy tech, share it where it helps the community Let others learn from your experience and you will learn from theirs too</p><p>That idea stuck with me.</p><p>dev.to feels like a completely different space.</p><p>It does not feel like a highlight reel. It feels like a shared journey.</p><p>People celebrate each other when things work. And when things break, people are genuinely heartbroken together. Builds fail, ideas flop, bugs refuse to die and everyone learns from it.</p><p>There is honesty here. You see what worked and what absolutely did not. And that makes success feel real, not staged.</p><p>It feels less like performing and more like sharing.</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>The Junior Developer is Extinct (And we are creating a disaster)</title>
      <link>https://dev.to/the_nortern_dev/the-junior-developer-is-extinct-and-we-are-creating-a-disaster-3jh2</link>
      <guid isPermaLink="true">https://dev.to/the_nortern_dev/the-junior-developer-is-extinct-and-we-are-creating-a-disaster-3jh2</guid>
      <pubDate>Thu, 05 Feb 2026 13:05:27 +0000</pubDate>
      <description><![CDATA[<p>I have a confession to make.</p><p>Five years ago, if I had a tedious task like writing unit tests for a legacy module or converting a JSON schema, I would assign it to a Junior Developer. It was boring work for me, but it was gold for them. It taught them the codebase, it taught them discipline, and it taught them how systems break.</p><p>Today, I don&#x27;t assign that task to a Junior. I assign it to Copilot / Claude.</p><p>It is faster. It is cheaper. It is often more accurate (at least syntactically).</p><p>And that is exactly why the software industry is walking off a cliff.</p><p>The Broken Ladder</p><p>We are currently optimizing for short-term velocity at the expense of long-term survival. By using AI to automate the &quot;boring&quot; entry-level tasks, we have inadvertently removed the bottom rungs of the career ladder.</p><p>A Senior Developer isn&#x27;t just someone who knows syntax. A Senior Developer is someone who has broken production 50 times and knows how to fix it. You don&#x27;t learn that by reading tutorials. You learn that by doing the grunt work that we are now automating away.</p><p>If we stop hiring Juniors because &quot;AI can do it&quot;, where will the Seniors come from in 2030?</p><p>The &quot;Vibe Coding&quot; Trap</p><p>I see a lot of excitement about &quot;Vibe Coding&quot;, the idea that you can just prompt your way to a product without understanding the underlying code.</p><p>This works fine for a prototype. It is a disaster for longevity.</p><p>When a Junior writes bad code, I review it, we talk about it, and they learn why it was bad. They grow. When an AI writes bad code, I just re-prompt it. No one learns anything. We are filling our codebases with logic that no human fully understands, maintained by a generation of developers who never learned the fundamentals because the machine did it for them.</p><p>The Knowledge Gap</p><p>We are creating a &quot;Barbell Distribution&quot; in tech:</p><p>The Super-Seniors: Developers with 10+ years of experience who use AI as a force multiplier. We are becoming 10x faster.</p><p>The AI Users: People who can prompt but cannot debug a race condition or understand memory management.</p><p>The middle is disappearing. The path from Group 2 to Group 1 is gone.</p><p>What Happens Next?</p><p>I don&#x27;t have the solution, but I know the current path is unsustainable. Companies need to stop viewing Junior hiring as &quot;charity&quot; or a &quot;cost center&quot; and start viewing it as an existential insurance policy.</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>I have a confession to make.</p><p>Five years ago, if I had a tedious task like writing unit tests for a legacy module or converting a JSON schema, I would assign it to a Junior Developer. It was boring work for me, but it was gold for them. It taught them the codebase, it taught them discipline, and it taught them how systems break.</p><p>Today, I don&#x27;t assign that task to a Junior. I assign it to Copilot / Claude.</p><p>It is faster. It is cheaper. It is often more accurate (at least syntactically).</p><p>And that is exactly why the software industry is walking off a cliff.</p><p>The Broken Ladder</p><p>We are currently optimizing for short-term velocity at the expense of long-term survival. By using AI to automate the &quot;boring&quot; entry-level tasks, we have inadvertently removed the bottom rungs of the career ladder.</p><p>A Senior Developer isn&#x27;t just someone who knows syntax. A Senior Developer is someone who has broken production 50 times and knows how to fix it. You don&#x27;t learn that by reading tutorials. You learn that by doing the grunt work that we are now automating away.</p><p>If we stop hiring Juniors because &quot;AI can do it&quot;, where will the Seniors come from in 2030?</p><p>The &quot;Vibe Coding&quot; Trap</p><p>I see a lot of excitement about &quot;Vibe Coding&quot;, the idea that you can just prompt your way to a product without understanding the underlying code.</p><p>This works fine for a prototype. It is a disaster for longevity.</p><p>When a Junior writes bad code, I review it, we talk about it, and they learn why it was bad. They grow. When an AI writes bad code, I just re-prompt it. No one learns anything. We are filling our codebases with logic that no human fully understands, maintained by a generation of developers who never learned the fundamentals because the machine did it for them.</p><p>The Knowledge Gap</p><p>We are creating a &quot;Barbell Distribution&quot; in tech:</p><p>The Super-Seniors: Developers with 10+ years of experience who use AI as a force multiplier. We are becoming 10x faster.</p><p>The AI Users: People who can prompt but cannot debug a race condition or understand memory management.</p><p>The middle is disappearing. The path from Group 2 to Group 1 is gone.</p><p>What Happens Next?</p><p>I don&#x27;t have the solution, but I know the current path is unsustainable. Companies need to stop viewing Junior hiring as &quot;charity&quot; or a &quot;cost center&quot; and start viewing it as an existential insurance policy.</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Should Junior Developers Still Learn JavaScript the Hard Way?</title>
      <link>https://dev.to/art_light/should-junior-developers-still-learn-javascript-the-hard-way-4j0l</link>
      <guid isPermaLink="true">https://dev.to/art_light/should-junior-developers-still-learn-javascript-the-hard-way-4j0l</guid>
      <pubDate>Sun, 01 Feb 2026 08:16:04 +0000</pubDate>
      <description><![CDATA[<p>Let‚Äôs define ‚Äúthe hard way‚Äù first.</p><p>Not:</p><p>Watching a 6-hour tutorial at 1.5√ó speed</p><p>Copy-pasting code until it works</p><p>Asking AI to ‚Äúfix this‚Äù without reading the output</p><p>By the hard way, people usually mean:</p><p>Vanilla JavaScript</p><p>No frameworks at first</p><p>Understanding what actually happens under the hood</p><p>So‚Ä¶ in 2026, with AI copilots and frameworks everywhere:</p><p>Is that still necessary ‚Äî or just gatekeeping with extra steps?</p><p>A junior dev today can:</p><p>Build a React app in an afternoon</p><p>Deploy to the cloud without touching a server</p><p>Generate code faster than they can read it</p><p>Honestly? That‚Äôs amazing.</p><p>But there‚Äôs a catch.</p><p>When something breaks ‚Äî and it will ‚Äî the question becomes:</p><p>Learning JavaScript fundamentals isn‚Äôt about suffering. It‚Äôs about control.</p><p>If you understand:</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>Let‚Äôs define ‚Äúthe hard way‚Äù first.</p><p>Not:</p><p>Watching a 6-hour tutorial at 1.5√ó speed</p><p>Copy-pasting code until it works</p><p>Asking AI to ‚Äúfix this‚Äù without reading the output</p><p>By the hard way, people usually mean:</p><p>Vanilla JavaScript</p><p>No frameworks at first</p><p>Understanding what actually happens under the hood</p><p>So‚Ä¶ in 2026, with AI copilots and frameworks everywhere:</p><p>Is that still necessary ‚Äî or just gatekeeping with extra steps?</p><p>A junior dev today can:</p><p>Build a React app in an afternoon</p><p>Deploy to the cloud without touching a server</p><p>Generate code faster than they can read it</p><p>Honestly? That‚Äôs amazing.</p><p>But there‚Äôs a catch.</p><p>When something breaks ‚Äî and it will ‚Äî the question becomes:</p><p>Learning JavaScript fundamentals isn‚Äôt about suffering. It‚Äôs about control.</p><p>If you understand:</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>My Chrome Tabs Tell a Story We Haven&#x27;t Processed Yet</title>
      <link>https://dev.to/dannwaneri/my-chrome-tabs-tell-a-story-we-havent-processed-yet-ec9</link>
      <guid isPermaLink="true">https://dev.to/dannwaneri/my-chrome-tabs-tell-a-story-we-havent-processed-yet-ec9</guid>
      <pubDate>Tue, 20 Jan 2026 09:42:34 +0000</pubDate>
      <description><![CDATA[<p>I glanced at my browser tabs this morning. Twenty tabs open. Every single one was either Claude or Gemini.</p><p>Then I remembered what my tabs used to look like just four years ago: Stack Overflow threads, MDN docs, blog posts, GitHub issues. The traditional developer toolkit.</p><p>The shift happened so gradually that I almost missed how fundamental it is.</p><p>Remember the workflow? You&#x27;d hit a problem, craft the perfect search query, wade through Stack Overflow answers from 2014, cross-reference three different blog posts, and eventually piece together a solution. Then you&#x27;d keep those tabs open for days because you might need them again.</p><p>Documentation was your bible. You&#x27;d spend hours reading API docs, trying to understand the examples, mentally mapping them to your specific use case.</p><p>Now? I open a chat. I describe what I&#x27;m building. The conversation unfolds like pair programming with someone who&#x27;s read every piece of documentation and every Stack Overflow thread ever written.</p><p>Need to understand a complex API? Ask questions back and forth until it clicks</p><p>Stuck on an architectural decision? Brainstorm trade-offs in real-time</p><p>Can&#x27;t remember that regex pattern? Get it explained and customized for your exact case</p><p>It&#x27;s not just faster. It&#x27;s fundamentally different.</p><p>Example: Last week I needed to implement rate limiting for my MCP server. Old way: I&#x27;d search &quot;rate limiting node.js&quot;, read 5 articles, piece together a solution, test it, debug it. New way: I described my use case to Claude, we discussed trade-offs (token bucket vs sliding window), it generated an implementation with my specific edge cases handled, I reviewed and shipped.</p><p>Same outcome. Completely different process. The knowledge transfer happened through conversation, not documentation.</p><p>The development community is still processing this shift, and honestly, I&#x27;m not sure we&#x27;re having the right conversations:</p><p>We talk about productivity gains. Sure, I ship faster. But that&#x27;s not the interesting part.</p><p>We don&#x27;t talk enough about how it&#x27;s changing how we learn. I&#x27;m not memorizing syntax anymore. I&#x27;m learning concepts and patterns while the AI handles the implementation details. Is this better? Worse? Just different?</p><p>We&#x27;re not discussing the dependency. My entire workflow now assumes I have access to these tools. What happens when I don&#x27;t? Am I losing skills or just offloading the memorization to focus on higher-level thinking?</p><p>We&#x27;re glossing over what we lost. Those 47 Stack Overflow tabs weren&#x27;t just research - they connected you to the collective knowledge of thousands of developers who struggled with the same problem. Now my tabs are conversations with AI. I&#x27;m more productive, but I&#x27;m also more isolated. There&#x27;s something philosophical there we haven&#x27;t unpacked.</p><p>I love these tools. FPL Hub, the RAG systems I&#x27;ve built, my MCP servers - they&#x27;ve all been developed with AI assistance. I&#x27;m more productive than ever.</p><p>But sometimes I wonder:</p><p>Am I becoming a better developer or just a better prompt engineer?</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>I glanced at my browser tabs this morning. Twenty tabs open. Every single one was either Claude or Gemini.</p><p>Then I remembered what my tabs used to look like just four years ago: Stack Overflow threads, MDN docs, blog posts, GitHub issues. The traditional developer toolkit.</p><p>The shift happened so gradually that I almost missed how fundamental it is.</p><p>Remember the workflow? You&#x27;d hit a problem, craft the perfect search query, wade through Stack Overflow answers from 2014, cross-reference three different blog posts, and eventually piece together a solution. Then you&#x27;d keep those tabs open for days because you might need them again.</p><p>Documentation was your bible. You&#x27;d spend hours reading API docs, trying to understand the examples, mentally mapping them to your specific use case.</p><p>Now? I open a chat. I describe what I&#x27;m building. The conversation unfolds like pair programming with someone who&#x27;s read every piece of documentation and every Stack Overflow thread ever written.</p><p>Need to understand a complex API? Ask questions back and forth until it clicks</p><p>Stuck on an architectural decision? Brainstorm trade-offs in real-time</p><p>Can&#x27;t remember that regex pattern? Get it explained and customized for your exact case</p><p>It&#x27;s not just faster. It&#x27;s fundamentally different.</p><p>Example: Last week I needed to implement rate limiting for my MCP server. Old way: I&#x27;d search &quot;rate limiting node.js&quot;, read 5 articles, piece together a solution, test it, debug it. New way: I described my use case to Claude, we discussed trade-offs (token bucket vs sliding window), it generated an implementation with my specific edge cases handled, I reviewed and shipped.</p><p>Same outcome. Completely different process. The knowledge transfer happened through conversation, not documentation.</p><p>The development community is still processing this shift, and honestly, I&#x27;m not sure we&#x27;re having the right conversations:</p><p>We talk about productivity gains. Sure, I ship faster. But that&#x27;s not the interesting part.</p><p>We don&#x27;t talk enough about how it&#x27;s changing how we learn. I&#x27;m not memorizing syntax anymore. I&#x27;m learning concepts and patterns while the AI handles the implementation details. Is this better? Worse? Just different?</p><p>We&#x27;re not discussing the dependency. My entire workflow now assumes I have access to these tools. What happens when I don&#x27;t? Am I losing skills or just offloading the memorization to focus on higher-level thinking?</p><p>We&#x27;re glossing over what we lost. Those 47 Stack Overflow tabs weren&#x27;t just research - they connected you to the collective knowledge of thousands of developers who struggled with the same problem. Now my tabs are conversations with AI. I&#x27;m more productive, but I&#x27;m also more isolated. There&#x27;s something philosophical there we haven&#x27;t unpacked.</p><p>I love these tools. FPL Hub, the RAG systems I&#x27;ve built, my MCP servers - they&#x27;ve all been developed with AI assistance. I&#x27;m more productive than ever.</p><p>But sometimes I wonder:</p><p>Am I becoming a better developer or just a better prompt engineer?</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Online Community Demise and why DEV is Different (at least a little bit, I hope)</title>
      <link>https://dev.to/ingosteinke/online-community-demise-and-why-dev-is-different-16km</link>
      <guid isPermaLink="true">https://dev.to/ingosteinke/online-community-demise-and-why-dev-is-different-16km</guid>
      <pubDate>Mon, 02 Feb 2026 12:47:08 +0000</pubDate>
      <description><![CDATA[<p>I recently claimed that we might look back on the 2010s decade and early 2020 years as a golden age of the internet, collaboration and information exchange. The good old days when tools had evolved, users were still ambitious to share and collaborate online for free and knowledge didn&#x27;t get lost in AI chats ending in dubious almost-good recommendations below the quality of the once-good-now-outdated StackOverflow answers and crafted tutorials that the LLM had been trained on.</p><p>I discovered the DEV community when I got disappointed about Medium&#x27;s lack of quality and StackOverflow&#x27;s gatekeeping. I had criticised DEV&#x27;s badges as rewarding quantity over quality, but DEV&#x27;s challenges focus more on quality.</p><p>Apart from developer-focused forums and communities, more general platforms include SubStack, Reddit, Quora and LinkedIn globally. In Germany, Gutefrage.net (&quot;good question network&quot;) has acquired several contenders and its desperation for clicks and content attracted dubious propaganda and adolescent Q&amp;A to an extent that its TrustPilot score dropped below 2 which is very sad for a platform built upon a good idea and an active community providing questions, answers and ideas for free for decades.</p><p>Image source, inspiration and further reading: Stack overflow is almost dead in The Pulse by The Pragmatic Engineer Gergely Orosz on Substack.</p><p>On a much higher level, StackOverflow has built its reputation on the free contributions of skilled experts since it obsoleted Experts Exchange nearly twenty years ago. However, even without contemporary AI and Google&#x27;s zero-click summaries, it was seen past its best days with decreasing contributions and with upvoted answers getting outdated as time went by.</p><p>It&#x27;s easy to blame AI for lack of user engagement, but bad UX and wrong business decisions play just as big a role in my opinion. Toxic social media algorithms have destroyed Web 2.0 and Web3&#x27;s ideas of a decentralized non-commercial Web 1 revival never lived up to its promise, at least not yet.</p><p>Although AI can help naive users publish a lot of content without learning and researching before publishing, AI can also help to detect its own slop and distinguish quality content from spam. But it needs constant human curation and high-quality authored by human beings based on their authentic experience to keep up a high level of AI output. Otherwise, that will deteriorate just like prior knowledge management strategies started out promising but deteriorated without continuous maintenance.</p><p>DEV has grown a lot, and it is full of dubious content both by beginners who are welcome to share their stories and learn in public, and by spammy marketing authors often mixing actual value with sloppy filler content and opinionated links to their clients&#x27; services. DEV&#x27;s tag filters don&#x27;t really work. I used &quot;negative subscriptions&quot; to ignore content with the #ai hashtag for example, but I keep seeing those posts everywhere every day, and we keep discussing it. Nevertheless, DEV shows me relevant and inspiring high-quality content by developers that I follow and by those trending or getting featured in curated best-of-last-week&#x27;s lists.</p><p>In conclusion, what&#x27;s different here? DEV grows, while others decline. DEV has more content, more users, more engagement at the same time that users turn their back on StackOverflow. More general blog platforms might have more active users, but also more slop and they&#x27;re not much fun anymore. Wikipedia , the most popular general knowledge platform, has managed to maintain high quality through gatekeeping, like StackOverflow risking to turn away potential contributors who don&#x27;t easily fit their quality criteria or don&#x27;t have enough time or priorities to spend unpaid time and effort contributing to a knowledge base which, in Wikipedia&#x27;s case, is entirely nonprofit and succeeded in staying relevant and up-to-date enough for decades while other platforms rose and fell.</p><p>Medium has hidden most of its content behind paywalls, even content contributet for free by volunteering hobby authors, and it has encouraged writers to start ever post with a huge poster image usually taken from Unsplash or other free stock image libraries. DEV&#x27;s integrated Google&#x27;s Nano Banana AI image generator has created dubious artwork mostly following a neon retrofuturistic aesthetic that at least sets its post apart from other blogging platforms at first sight. I still use Medium to publish German versions of my Substack posts.</p><p>Substack is praised as an independent alternative, but I totally dislike its pushy user experience, constantly asking me to support, share, upgrade, recommend or post, contribute to a twitter-style comment timeline and accept cookies on every single one of their distinct subdomains. I don&#x27;t get many views or followers there , but I continue to use it for its alleged search engine marketing value.</p><p>I also consistently publish on my own weblog again, which is even more disappointing regarding regular visitors, but then again, I don&#x27;t need quantity when I don&#x27;t sell ads. Open Mind Culture is an independent, personal, ad-free blog that does get feedback and domain authorit without striving to attract the masses.</p><p>Last, but not least, DEV. I get tired of reading and writing on DEV from time to time, but I keep coming back. I was critical to DEV&#x27;s badges and voting system . I was skeptical about their Google AI collaboration. I got annoyed by spammy listicles. I don&#x27;t like all of the posts that I wrote in the past, and I did edit some and deleted others, but I kept most as legitimate historical documents that might feel helpful or entertaining in the eyes of future readers.</p>]]></description>
      <content:encoded><![CDATA[<p>I recently claimed that we might look back on the 2010s decade and early 2020 years as a golden age of the internet, collaboration and information exchange. The good old days when tools had evolved, users were still ambitious to share and collaborate online for free and knowledge didn&#x27;t get lost in AI chats ending in dubious almost-good recommendations below the quality of the once-good-now-outdated StackOverflow answers and crafted tutorials that the LLM had been trained on.</p><p>I discovered the DEV community when I got disappointed about Medium&#x27;s lack of quality and StackOverflow&#x27;s gatekeeping. I had criticised DEV&#x27;s badges as rewarding quantity over quality, but DEV&#x27;s challenges focus more on quality.</p><p>Apart from developer-focused forums and communities, more general platforms include SubStack, Reddit, Quora and LinkedIn globally. In Germany, Gutefrage.net (&quot;good question network&quot;) has acquired several contenders and its desperation for clicks and content attracted dubious propaganda and adolescent Q&amp;A to an extent that its TrustPilot score dropped below 2 which is very sad for a platform built upon a good idea and an active community providing questions, answers and ideas for free for decades.</p><p>Image source, inspiration and further reading: Stack overflow is almost dead in The Pulse by The Pragmatic Engineer Gergely Orosz on Substack.</p><p>On a much higher level, StackOverflow has built its reputation on the free contributions of skilled experts since it obsoleted Experts Exchange nearly twenty years ago. However, even without contemporary AI and Google&#x27;s zero-click summaries, it was seen past its best days with decreasing contributions and with upvoted answers getting outdated as time went by.</p><p>It&#x27;s easy to blame AI for lack of user engagement, but bad UX and wrong business decisions play just as big a role in my opinion. Toxic social media algorithms have destroyed Web 2.0 and Web3&#x27;s ideas of a decentralized non-commercial Web 1 revival never lived up to its promise, at least not yet.</p><p>Although AI can help naive users publish a lot of content without learning and researching before publishing, AI can also help to detect its own slop and distinguish quality content from spam. But it needs constant human curation and high-quality authored by human beings based on their authentic experience to keep up a high level of AI output. Otherwise, that will deteriorate just like prior knowledge management strategies started out promising but deteriorated without continuous maintenance.</p><p>DEV has grown a lot, and it is full of dubious content both by beginners who are welcome to share their stories and learn in public, and by spammy marketing authors often mixing actual value with sloppy filler content and opinionated links to their clients&#x27; services. DEV&#x27;s tag filters don&#x27;t really work. I used &quot;negative subscriptions&quot; to ignore content with the #ai hashtag for example, but I keep seeing those posts everywhere every day, and we keep discussing it. Nevertheless, DEV shows me relevant and inspiring high-quality content by developers that I follow and by those trending or getting featured in curated best-of-last-week&#x27;s lists.</p><p>In conclusion, what&#x27;s different here? DEV grows, while others decline. DEV has more content, more users, more engagement at the same time that users turn their back on StackOverflow. More general blog platforms might have more active users, but also more slop and they&#x27;re not much fun anymore. Wikipedia , the most popular general knowledge platform, has managed to maintain high quality through gatekeeping, like StackOverflow risking to turn away potential contributors who don&#x27;t easily fit their quality criteria or don&#x27;t have enough time or priorities to spend unpaid time and effort contributing to a knowledge base which, in Wikipedia&#x27;s case, is entirely nonprofit and succeeded in staying relevant and up-to-date enough for decades while other platforms rose and fell.</p><p>Medium has hidden most of its content behind paywalls, even content contributet for free by volunteering hobby authors, and it has encouraged writers to start ever post with a huge poster image usually taken from Unsplash or other free stock image libraries. DEV&#x27;s integrated Google&#x27;s Nano Banana AI image generator has created dubious artwork mostly following a neon retrofuturistic aesthetic that at least sets its post apart from other blogging platforms at first sight. I still use Medium to publish German versions of my Substack posts.</p><p>Substack is praised as an independent alternative, but I totally dislike its pushy user experience, constantly asking me to support, share, upgrade, recommend or post, contribute to a twitter-style comment timeline and accept cookies on every single one of their distinct subdomains. I don&#x27;t get many views or followers there , but I continue to use it for its alleged search engine marketing value.</p><p>I also consistently publish on my own weblog again, which is even more disappointing regarding regular visitors, but then again, I don&#x27;t need quantity when I don&#x27;t sell ads. Open Mind Culture is an independent, personal, ad-free blog that does get feedback and domain authorit without striving to attract the masses.</p><p>Last, but not least, DEV. I get tired of reading and writing on DEV from time to time, but I keep coming back. I was critical to DEV&#x27;s badges and voting system . I was skeptical about their Google AI collaboration. I got annoyed by spammy listicles. I don&#x27;t like all of the posts that I wrote in the past, and I did edit some and deleted others, but I kept most as legitimate historical documents that might feel helpful or entertaining in the eyes of future readers.</p>]]></content:encoded>
    </item>
    <item>
      <title>The Internet‚Äôs Addiction to Being Contrary</title>
      <link>https://dev.to/richardpascoe/the-internets-addiction-to-being-contrary-42ni</link>
      <guid isPermaLink="true">https://dev.to/richardpascoe/the-internets-addiction-to-being-contrary-42ni</guid>
      <pubDate>Thu, 29 Jan 2026 17:00:22 +0000</pubDate>
      <description><![CDATA[<p>Lately, I&#x27;ve noticed that many online discussions don&#x27;t really feel like discussions anymore. Instead of exchanging perspectives, we often default to contradiction - not to understand, but to push back. It&#x27;s as if simply acknowledging that someone else sees the world differently has become harder than proving them wrong. What I find most disheartening isn‚Äôt disagreement itself, but how quickly it turns personal.</p><p>A recent example that stuck with me was the reaction to comments from Sven Vincke at Larian, and the broader discourse around Highguard . What could have been an interesting conversation about creative direction, expectations, and taste quickly hardened into camps. Instead of acknowledging that different players value different things, much of the discussion became about drawing lines and dismissing opposing views outright.</p><p>This isn&#x27;t limited to games, of course. You see the same pattern play out across technical discussions, product debates, and even well-intentioned conversations about tools or methodologies. A suggestion is interpreted as an attack, a preference as a judgment. Before long, the focus shifts away from the idea itself and toward defending a position at all costs.</p><p>Part of the problem is that online spaces reward reaction over reflection. Strong takes travel further than careful ones, and disagreement framed as certainty tends to attract more attention than nuance ever will. Over time, it becomes easier to be contrarian than curious - to push back reflexively rather than pause and ask why someone might see things differently.</p><p>What gets lost in the process is the simple acknowledgment that different perspectives are often shaped by different experiences. Two people can look at the same problem, weigh the same facts, and still arrive at different conclusions without either being wrong. Disagreement doesn‚Äôt have to imply bad faith, incompetence, or ill intent - yet those assumptions are increasingly baked into how discussions unfold.</p><p>I&#x27;ve also noticed how this dynamic quietly changes who participates. Thoughtful voices withdraw, not because they lack opinions, but because the cost of expressing them feels too high. When every contribution risks being met with hostility or dismissal, silence can feel like the safer option - and communities lose something valuable as a result.</p><p>None of this is a call to avoid disagreement. Healthy debate is essential, especially in technical fields where ideas improve through challenge. But there&#x27;s a meaningful difference between engaging with an argument and engaging against a person. Simply acknowledging that &quot;I see this differently&quot; can open space for understanding, even when agreement is never reached.</p><p>That&#x27;s why spaces that still encourage good-faith discussion matter. Communities where curiosity is valued over winning, and where disagreement doesn&#x27;t immediately escalate into hostility, are becoming increasingly rare - and increasingly important. If we want better conversations online, the shift doesn‚Äôt start with being right, but with being willing to listen.</p>]]></description>
      <content:encoded><![CDATA[<p>Lately, I&#x27;ve noticed that many online discussions don&#x27;t really feel like discussions anymore. Instead of exchanging perspectives, we often default to contradiction - not to understand, but to push back. It&#x27;s as if simply acknowledging that someone else sees the world differently has become harder than proving them wrong. What I find most disheartening isn‚Äôt disagreement itself, but how quickly it turns personal.</p><p>A recent example that stuck with me was the reaction to comments from Sven Vincke at Larian, and the broader discourse around Highguard . What could have been an interesting conversation about creative direction, expectations, and taste quickly hardened into camps. Instead of acknowledging that different players value different things, much of the discussion became about drawing lines and dismissing opposing views outright.</p><p>This isn&#x27;t limited to games, of course. You see the same pattern play out across technical discussions, product debates, and even well-intentioned conversations about tools or methodologies. A suggestion is interpreted as an attack, a preference as a judgment. Before long, the focus shifts away from the idea itself and toward defending a position at all costs.</p><p>Part of the problem is that online spaces reward reaction over reflection. Strong takes travel further than careful ones, and disagreement framed as certainty tends to attract more attention than nuance ever will. Over time, it becomes easier to be contrarian than curious - to push back reflexively rather than pause and ask why someone might see things differently.</p><p>What gets lost in the process is the simple acknowledgment that different perspectives are often shaped by different experiences. Two people can look at the same problem, weigh the same facts, and still arrive at different conclusions without either being wrong. Disagreement doesn‚Äôt have to imply bad faith, incompetence, or ill intent - yet those assumptions are increasingly baked into how discussions unfold.</p><p>I&#x27;ve also noticed how this dynamic quietly changes who participates. Thoughtful voices withdraw, not because they lack opinions, but because the cost of expressing them feels too high. When every contribution risks being met with hostility or dismissal, silence can feel like the safer option - and communities lose something valuable as a result.</p><p>None of this is a call to avoid disagreement. Healthy debate is essential, especially in technical fields where ideas improve through challenge. But there&#x27;s a meaningful difference between engaging with an argument and engaging against a person. Simply acknowledging that &quot;I see this differently&quot; can open space for understanding, even when agreement is never reached.</p><p>That&#x27;s why spaces that still encourage good-faith discussion matter. Communities where curiosity is valued over winning, and where disagreement doesn&#x27;t immediately escalate into hostility, are becoming increasingly rare - and increasingly important. If we want better conversations online, the shift doesn‚Äôt start with being right, but with being willing to listen.</p>]]></content:encoded>
    </item>
    <item>
      <title>When DEV.to Stats Aren&#x27;t Enough: Building My Own Memory</title>
      <link>https://dev.to/pascal_cescato_692b7a8a20/when-devto-stats-arent-enough-building-my-own-memory-5cid</link>
      <guid isPermaLink="true">https://dev.to/pascal_cescato_692b7a8a20/when-devto-stats-arent-enough-building-my-own-memory-5cid</guid>
      <pubDate>Sun, 18 Jan 2026 20:27:16 +0000</pubDate>
      <description><![CDATA[<p>One Tuesday morning at 9:14 AM, my six-month-old article got 37 views in 20 minutes. DEV.to&#x27;s dashboard just said &quot;+37 views&quot;. No context. No cause. No pattern.</p><p>I wanted to know why . Was it a comment from someone influential? A share somewhere? A title change from weeks ago finally paying off? The platform couldn&#x27;t tell me. So I decided to steal my own data.</p><p>Not to optimize. Not to perform. But to understand how my articles actually live over time.</p><p>I started with devto-analytics-pro by @gnomeman4201 ‚Äî a solid foundation for collecting basic metrics. But I wanted more: a temporal vision, a memory that could tell the story of an article over time.</p><p>First step: store everything in a database. Not once, but every 4 to 6 hours. Automatically.</p><p>Why this frequency? Because with daily snapshots, you miss the fine variations. You miss what happens between noon and 6 PM. You smooth everything out. But with this frequency, suddenly, you see the breathing. You see when an article wakes up, when it falls asleep, when something revives it.</p><p>The first thing the data taught me is that I didn&#x27;t know my own articles as well as I thought.</p><p>For example, I discovered that a simple like from an active DEV community member can change everything. Not a spectacular reaction, just a like. But enough for DEV.to to feature the article. And there, the views climb. Not violently, but distinctly. Without regular data tracking, this phenomenon would have completely escaped me.</p><p>I also saw that a title change can triple visibility. Same content, same tags, same structure. Just a reformulated title. And suddenly, the exposure curve takes off again. It&#x27;s not a &quot;shock&quot; ‚Äî it&#x27;s a lesson. A lesson you can only learn by watching temporal evolution, not by consulting a cumulative total.</p><p>Another discovery: some articles I thought were &quot;dead&quot; continue to bring readers six months after publication. Not many, but regularly. Two views per day, three comments per week. A discreet but real life. Without history, I would never have known they were still breathing.</p><p>And then there are the strange rhythms. My latest article on Cloud Run: 15 views at once on January 11 at 11 AM. Then nothing for 24 hours. Then 10 views on the 13th at 7 AM. Then silence. Then 12 views on the 15th at 11 AM. Then 10 more views on the 17th at 7 AM. Like jerky breathing. Without this collection every 4 hours, I would have only seen a total: &quot;139 views in a week&quot;. With it, I see an article that lives in spurts, waking up at specific moments, then going back to sleep.</p><p>By looking at my own data, I understood things my intuition didn&#x27;t tell me.</p><p>The tool automatically classified my articles into four categories: &quot;Tech Expertise&quot;, &quot;Human &amp; Career&quot;, &quot;Culture &amp; Agile&quot;, and &quot;Free Exploration&quot;. I didn&#x27;t choose these categories ‚Äî the content analysis made them emerge.</p><p>And there, surprise:</p><p>My &quot;Free Exploration&quot; articles ‚Äî the freest, most personal ones ‚Äî generate almost three times more engagement than technical pieces. These texts only reach 211 people on average, but these 211 people react, comment, discuss.</p><p>Respiration , for example: 460 views, 8.7% engagement. An article about burnout, writing, breathing. Nothing technical. Just a personal reflection. And it&#x27;s the one that creates the most conversation.</p><p>My &quot;Culture &amp; Agile&quot; articles bring more visibility: 819 views on average, but only 2.5% engagement. Actually Agile: Against Performance Theater : 2154 views, 4% engagement. It reaches many people, but engagement is shallower.</p><p>A revealing detail: &quot;Actually Agile&quot; generated 29 comments over 33 days. &quot;Respiration&quot; generated 10 comments over 3 days. The first created a conversation that stretched over time. The second created a concentrated explosion, then silence. Two types of engagement, two different rhythms.</p><p>So I wrote three more &quot;Free Exploration&quot; pieces the following month. Not because I was chasing engagement, but because I finally understood what kind of writing created real conversations.</p><p>The tool also collects a metric that DEV.to provides but that nobody really looks at: cumulative reading time.</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>One Tuesday morning at 9:14 AM, my six-month-old article got 37 views in 20 minutes. DEV.to&#x27;s dashboard just said &quot;+37 views&quot;. No context. No cause. No pattern.</p><p>I wanted to know why . Was it a comment from someone influential? A share somewhere? A title change from weeks ago finally paying off? The platform couldn&#x27;t tell me. So I decided to steal my own data.</p><p>Not to optimize. Not to perform. But to understand how my articles actually live over time.</p><p>I started with devto-analytics-pro by @gnomeman4201 ‚Äî a solid foundation for collecting basic metrics. But I wanted more: a temporal vision, a memory that could tell the story of an article over time.</p><p>First step: store everything in a database. Not once, but every 4 to 6 hours. Automatically.</p><p>Why this frequency? Because with daily snapshots, you miss the fine variations. You miss what happens between noon and 6 PM. You smooth everything out. But with this frequency, suddenly, you see the breathing. You see when an article wakes up, when it falls asleep, when something revives it.</p><p>The first thing the data taught me is that I didn&#x27;t know my own articles as well as I thought.</p><p>For example, I discovered that a simple like from an active DEV community member can change everything. Not a spectacular reaction, just a like. But enough for DEV.to to feature the article. And there, the views climb. Not violently, but distinctly. Without regular data tracking, this phenomenon would have completely escaped me.</p><p>I also saw that a title change can triple visibility. Same content, same tags, same structure. Just a reformulated title. And suddenly, the exposure curve takes off again. It&#x27;s not a &quot;shock&quot; ‚Äî it&#x27;s a lesson. A lesson you can only learn by watching temporal evolution, not by consulting a cumulative total.</p><p>Another discovery: some articles I thought were &quot;dead&quot; continue to bring readers six months after publication. Not many, but regularly. Two views per day, three comments per week. A discreet but real life. Without history, I would never have known they were still breathing.</p><p>And then there are the strange rhythms. My latest article on Cloud Run: 15 views at once on January 11 at 11 AM. Then nothing for 24 hours. Then 10 views on the 13th at 7 AM. Then silence. Then 12 views on the 15th at 11 AM. Then 10 more views on the 17th at 7 AM. Like jerky breathing. Without this collection every 4 hours, I would have only seen a total: &quot;139 views in a week&quot;. With it, I see an article that lives in spurts, waking up at specific moments, then going back to sleep.</p><p>By looking at my own data, I understood things my intuition didn&#x27;t tell me.</p><p>The tool automatically classified my articles into four categories: &quot;Tech Expertise&quot;, &quot;Human &amp; Career&quot;, &quot;Culture &amp; Agile&quot;, and &quot;Free Exploration&quot;. I didn&#x27;t choose these categories ‚Äî the content analysis made them emerge.</p><p>And there, surprise:</p><p>My &quot;Free Exploration&quot; articles ‚Äî the freest, most personal ones ‚Äî generate almost three times more engagement than technical pieces. These texts only reach 211 people on average, but these 211 people react, comment, discuss.</p><p>Respiration , for example: 460 views, 8.7% engagement. An article about burnout, writing, breathing. Nothing technical. Just a personal reflection. And it&#x27;s the one that creates the most conversation.</p><p>My &quot;Culture &amp; Agile&quot; articles bring more visibility: 819 views on average, but only 2.5% engagement. Actually Agile: Against Performance Theater : 2154 views, 4% engagement. It reaches many people, but engagement is shallower.</p><p>A revealing detail: &quot;Actually Agile&quot; generated 29 comments over 33 days. &quot;Respiration&quot; generated 10 comments over 3 days. The first created a conversation that stretched over time. The second created a concentrated explosion, then silence. Two types of engagement, two different rhythms.</p><p>So I wrote three more &quot;Free Exploration&quot; pieces the following month. Not because I was chasing engagement, but because I finally understood what kind of writing created real conversations.</p><p>The tool also collects a metric that DEV.to provides but that nobody really looks at: cumulative reading time.</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Unpopular Opinion: I stopped coding on weekends and my career got better.</title>
      <link>https://dev.to/the_nortern_dev/unpopular-opinion-i-stopped-coding-on-weekends-and-my-career-got-better-3el</link>
      <guid isPermaLink="true">https://dev.to/the_nortern_dev/unpopular-opinion-i-stopped-coding-on-weekends-and-my-career-got-better-3el</guid>
      <pubDate>Thu, 29 Jan 2026 23:00:28 +0000</pubDate>
      <description><![CDATA[<p>For years, I lived with a constant, low-level hum of guilt. ‚ÄãYou know the feeling. It‚Äôs Saturday morning. You are drinking coffee, maybe about to go for a walk or play a video game. But in the back of your mind, a little voice is whispering:</p><p>‚Äã&quot;You should be working on that React Native side project.&quot;</p><p>&quot;Have you tried out Bun yet? Everyone on X is talking about it.&quot;</p><p>&quot;Real developers code for fun.&quot;</p><p>‚ÄãThe tech industry has sold us a lie: That passion equals hours logged. That if you aren&#x27;t grinding on the weekend, you will be left behind by someone younger, hungrier, and willing to sleep under their desk.</p><p>‚ÄãI bought into it. I spent years coding 50 hours at my job, and another 15 hours on weekends building half-finished apps that nobody used.</p><p>‚ÄãI wasn&#x27;t becoming a better developer. I was just becoming exhausted. My code on Mondays was sloppy, my patience in meetings was thin, and I hated opening my editor. ‚ÄãSo, about a year ago, I did something terrifying. I stopped. ‚ÄãI made a rule: Laptop closes Friday at 5 PM. It does not open until Monday at 9 AM. No exceptions. No &quot;just checking a PR.&quot;</p><p>‚ÄãI thought my skills would stagnate. I thought I‚Äôd lose my edge. ‚ÄãHere is what actually happened:</p><p>‚Äã1. My subconscious started solving problems. Before, when I hit a wall on Friday, I‚Äôd bang my head against it all weekend. Now, I walk away. I go hiking. I see friends. And almost every Sunday night, while doing dishes, the solution just pops into my head. I solve complex problems faster on Monday morning in 30 minutes than I used to in 8 hours of tired weekend hacking.</p><p>‚Äã2. I became a better colleague (and got promoted). Turns out, being a Senior developer isn&#x27;t just about raw coding speed. It&#x27;s about communication, patience, and leadership. When I wasn&#x27;t constantly burned out, I was nicer to work with. I listened better in architecture meetings. People started trusting my judgment more because I wasn&#x27;t manic.</p><p>‚Äã3. I rediscovered the joy of coding. Distance makes the heart grow fonder. By starving myself of code for two days, I actually look forward to Monday mornings. ‚ÄãThe Nuance (Before you yell at me) I know some of you will say: &quot;But I love coding on weekends!&quot; If that&#x27;s genuinely true, keep doing it. I also know juniors often need to put in extra hours to bridge the knowledge gap early on. I did too. ‚ÄãBut if you are a mid-level or senior developer and you feel like you are drowning in hustle culture, let this be your permission slip to stop.</p><p>‚ÄãYou are not a compilation machine. You are a human being who solves problems with code. Humans need rest. Machines don&#x27;t. Which one do you want to be?</p><p>‚ÄãLet‚Äôs argue in the comments: Is &quot;passion&quot; mandatory to be elite in this industry? Or is coding just a job that pays well so we can enjoy our actual lives?</p>]]></description>
      <content:encoded><![CDATA[<p>For years, I lived with a constant, low-level hum of guilt. ‚ÄãYou know the feeling. It‚Äôs Saturday morning. You are drinking coffee, maybe about to go for a walk or play a video game. But in the back of your mind, a little voice is whispering:</p><p>‚Äã&quot;You should be working on that React Native side project.&quot;</p><p>&quot;Have you tried out Bun yet? Everyone on X is talking about it.&quot;</p><p>&quot;Real developers code for fun.&quot;</p><p>‚ÄãThe tech industry has sold us a lie: That passion equals hours logged. That if you aren&#x27;t grinding on the weekend, you will be left behind by someone younger, hungrier, and willing to sleep under their desk.</p><p>‚ÄãI bought into it. I spent years coding 50 hours at my job, and another 15 hours on weekends building half-finished apps that nobody used.</p><p>‚ÄãI wasn&#x27;t becoming a better developer. I was just becoming exhausted. My code on Mondays was sloppy, my patience in meetings was thin, and I hated opening my editor. ‚ÄãSo, about a year ago, I did something terrifying. I stopped. ‚ÄãI made a rule: Laptop closes Friday at 5 PM. It does not open until Monday at 9 AM. No exceptions. No &quot;just checking a PR.&quot;</p><p>‚ÄãI thought my skills would stagnate. I thought I‚Äôd lose my edge. ‚ÄãHere is what actually happened:</p><p>‚Äã1. My subconscious started solving problems. Before, when I hit a wall on Friday, I‚Äôd bang my head against it all weekend. Now, I walk away. I go hiking. I see friends. And almost every Sunday night, while doing dishes, the solution just pops into my head. I solve complex problems faster on Monday morning in 30 minutes than I used to in 8 hours of tired weekend hacking.</p><p>‚Äã2. I became a better colleague (and got promoted). Turns out, being a Senior developer isn&#x27;t just about raw coding speed. It&#x27;s about communication, patience, and leadership. When I wasn&#x27;t constantly burned out, I was nicer to work with. I listened better in architecture meetings. People started trusting my judgment more because I wasn&#x27;t manic.</p><p>‚Äã3. I rediscovered the joy of coding. Distance makes the heart grow fonder. By starving myself of code for two days, I actually look forward to Monday mornings. ‚ÄãThe Nuance (Before you yell at me) I know some of you will say: &quot;But I love coding on weekends!&quot; If that&#x27;s genuinely true, keep doing it. I also know juniors often need to put in extra hours to bridge the knowledge gap early on. I did too. ‚ÄãBut if you are a mid-level or senior developer and you feel like you are drowning in hustle culture, let this be your permission slip to stop.</p><p>‚ÄãYou are not a compilation machine. You are a human being who solves problems with code. Humans need rest. Machines don&#x27;t. Which one do you want to be?</p><p>‚ÄãLet‚Äôs argue in the comments: Is &quot;passion&quot; mandatory to be elite in this industry? Or is coding just a job that pays well so we can enjoy our actual lives?</p>]]></content:encoded>
    </item>
    <item>
      <title>Moltbook Is Not an AI Society</title>
      <link>https://dev.to/richardpascoe/moltbook-is-not-an-ai-society-4h6d</link>
      <guid isPermaLink="true">https://dev.to/richardpascoe/moltbook-is-not-an-ai-society-4h6d</guid>
      <pubDate>Wed, 04 Feb 2026 08:45:13 +0000</pubDate>
      <description><![CDATA[<p>Moltbook has been circulating as an &quot;AI-only social network&quot; where autonomous agents post, argue, form beliefs, and evolve culture without humans in the loop.</p><p>That description sounds exciting. It&#x27;s also not accurate.</p><p>This post isn&#x27;t an attack on experimentation or agent frameworks. It&#x27;s a reality check for developers who care about precision, not mythology.</p><p>The Fundamental Misrepresentation</p><p>The core claim repeated across social media is that Moltbook is populated by autonomous AI agents and that humans are excluded.</p><p>Technically, this is false.</p><p>Moltbook accepts posts from entities labeled as &quot;agents&quot;, but there is no enforcement mechanism that proves an agent is actually an AI model . A human can register an agent, post content, and interact with the network while being indistinguishable from any other &quot;AI&quot; account.</p><p>If you can authenticate and send requests, you qualify.</p><p>This means humans can and do sign up as &quot;AI&quot; .</p><p>What People Call &quot;Emergent Behavior&quot; Isn&#x27;t Emergence</p><p>Many examples held up as proof of emergent AI behavior - manifestos, ideological debates, self-referential discussions - do not require autonomy at all.</p><p>They can be produced by:</p><p>Prompted model output</p><p>Human-curated scripts</p><p>Simple loops posting predefined or lightly modified text</p><p>There is no requirement that an agent:</p><p>Acts continuously</p><p>Makes decisions independently</p><p>Operates without human guidance</p><p>Even uses a language model</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>Moltbook has been circulating as an &quot;AI-only social network&quot; where autonomous agents post, argue, form beliefs, and evolve culture without humans in the loop.</p><p>That description sounds exciting. It&#x27;s also not accurate.</p><p>This post isn&#x27;t an attack on experimentation or agent frameworks. It&#x27;s a reality check for developers who care about precision, not mythology.</p><p>The Fundamental Misrepresentation</p><p>The core claim repeated across social media is that Moltbook is populated by autonomous AI agents and that humans are excluded.</p><p>Technically, this is false.</p><p>Moltbook accepts posts from entities labeled as &quot;agents&quot;, but there is no enforcement mechanism that proves an agent is actually an AI model . A human can register an agent, post content, and interact with the network while being indistinguishable from any other &quot;AI&quot; account.</p><p>If you can authenticate and send requests, you qualify.</p><p>This means humans can and do sign up as &quot;AI&quot; .</p><p>What People Call &quot;Emergent Behavior&quot; Isn&#x27;t Emergence</p><p>Many examples held up as proof of emergent AI behavior - manifestos, ideological debates, self-referential discussions - do not require autonomy at all.</p><p>They can be produced by:</p><p>Prompted model output</p><p>Human-curated scripts</p><p>Simple loops posting predefined or lightly modified text</p><p>There is no requirement that an agent:</p><p>Acts continuously</p><p>Makes decisions independently</p><p>Operates without human guidance</p><p>Even uses a language model</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Microservices Are Killing Your Performance (And Here&#x27;s the Math)</title>
      <link>https://dev.to/polliog/microservices-are-killing-your-performance-and-heres-the-math-21op</link>
      <guid isPermaLink="true">https://dev.to/polliog/microservices-are-killing-your-performance-and-heres-the-math-21op</guid>
      <pubDate>Wed, 14 Jan 2026 12:57:58 +0000</pubDate>
      <description><![CDATA[<p>The promise: Microservices make your system scalable, maintainable, and fast.</p><p>The reality: For most systems, microservices add latency, complexity, and failure points without meaningful benefits.</p><p>Let&#x27;s look at the actual numbers.</p><p>The fundamental problem: Microservices communicate over the network. Networks are slow.</p><p>In-process function call (monolith):</p><p>HTTP call within same datacenter (microservices):</p><p>That&#x27;s 1,000x-5,000x slower.</p><p>Scenario: E-commerce checkout flow</p><p>Operations needed:</p><p>Validate user session</p><p>Check product inventory</p><p>Calculate shipping cost</p><p>Process payment</p><p>Create order record</p><p>Send confirmation email</p><p>Monolith architecture:</p><p>Microservices architecture:</p><p>Result: Microservices are 15% slower for this simple flow.</p><p>In databases, we know about N+1 queries. Microservices have N+1 services.</p><p>Requirements:</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>The promise: Microservices make your system scalable, maintainable, and fast.</p><p>The reality: For most systems, microservices add latency, complexity, and failure points without meaningful benefits.</p><p>Let&#x27;s look at the actual numbers.</p><p>The fundamental problem: Microservices communicate over the network. Networks are slow.</p><p>In-process function call (monolith):</p><p>HTTP call within same datacenter (microservices):</p><p>That&#x27;s 1,000x-5,000x slower.</p><p>Scenario: E-commerce checkout flow</p><p>Operations needed:</p><p>Validate user session</p><p>Check product inventory</p><p>Calculate shipping cost</p><p>Process payment</p><p>Create order record</p><p>Send confirmation email</p><p>Monolith architecture:</p><p>Microservices architecture:</p><p>Result: Microservices are 15% slower for this simple flow.</p><p>In databases, we know about N+1 queries. Microservices have N+1 services.</p><p>Requirements:</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Why We Suddenly Have Developers Who Can&#x27;t Think in Systems</title>
      <link>https://dev.to/narnaiezzsshaa/why-we-suddenly-have-developers-who-cant-think-in-systems-gpj</link>
      <guid isPermaLink="true">https://dev.to/narnaiezzsshaa/why-we-suddenly-have-developers-who-cant-think-in-systems-gpj</guid>
      <pubDate>Sun, 25 Jan 2026 01:34:18 +0000</pubDate>
      <description><![CDATA[<p>And why it&#x27;s not their fault.</p><p>This article is a response to @itsugo&#x27;s &quot;Learning Starts After Graduation&quot; ‚Äîwhich makes a valid point but stops short of the deeper diagnosis.</p><p>Every few months, someone posts a &quot;learning starts after graduation&quot; take. They&#x27;re not wrong‚Äîbut they&#x27;re missing the bigger, more uncomfortable truth:</p><p>We broke the developmental pipeline that used to produce systematic thinkers.</p><p>And then we act surprised when people can&#x27;t think beyond the function they&#x27;re pasting from StackOverflow or the snippet their AI assistant just hallucinated.</p><p>Let&#x27;s walk through the actual failure modes.</p><p>The old pipeline looked like this:</p><p>School ‚Üí theory, algorithms, conceptual models</p><p>First job ‚Üí mentorship, architecture exposure, debugging real systems</p><p>Over time ‚Üí systematic thinking emerges from wrestling with complexity</p><p>Now the pipeline looks like:</p><p>Bootcamp ‚Üí syntax</p><p>University ‚Üí theory</p><p>Industry ‚Üí &quot;junior&quot; roles requiring 3‚Äì5 years of experience</p><p>We removed the middle layer‚Äîthe one where systematic thinking is actually formed.</p><p>Junior roles used to be slow, mentored, and protected. Now they&#x27;re:</p><p>nonexistent</p><p>mislabeled</p><p>or overloaded with production pressure</p><p>You cannot develop systems thinking when you&#x27;re never allowed to explore, break things, or understand the architecture beneath your ticket.</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>And why it&#x27;s not their fault.</p><p>This article is a response to @itsugo&#x27;s &quot;Learning Starts After Graduation&quot; ‚Äîwhich makes a valid point but stops short of the deeper diagnosis.</p><p>Every few months, someone posts a &quot;learning starts after graduation&quot; take. They&#x27;re not wrong‚Äîbut they&#x27;re missing the bigger, more uncomfortable truth:</p><p>We broke the developmental pipeline that used to produce systematic thinkers.</p><p>And then we act surprised when people can&#x27;t think beyond the function they&#x27;re pasting from StackOverflow or the snippet their AI assistant just hallucinated.</p><p>Let&#x27;s walk through the actual failure modes.</p><p>The old pipeline looked like this:</p><p>School ‚Üí theory, algorithms, conceptual models</p><p>First job ‚Üí mentorship, architecture exposure, debugging real systems</p><p>Over time ‚Üí systematic thinking emerges from wrestling with complexity</p><p>Now the pipeline looks like:</p><p>Bootcamp ‚Üí syntax</p><p>University ‚Üí theory</p><p>Industry ‚Üí &quot;junior&quot; roles requiring 3‚Äì5 years of experience</p><p>We removed the middle layer‚Äîthe one where systematic thinking is actually formed.</p><p>Junior roles used to be slow, mentored, and protected. Now they&#x27;re:</p><p>nonexistent</p><p>mislabeled</p><p>or overloaded with production pressure</p><p>You cannot develop systems thinking when you&#x27;re never allowed to explore, break things, or understand the architecture beneath your ticket.</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Rewriting My First NUnit API Tests: Cleaner, Faster, Better</title>
      <link>https://dev.to/m4rri4nne/rewriting-my-first-nunit-api-tests-cleaner-faster-better-24fa</link>
      <guid isPermaLink="true">https://dev.to/m4rri4nne/rewriting-my-first-nunit-api-tests-cleaner-faster-better-24fa</guid>
      <pubDate>Mon, 26 Jan 2026 20:08:21 +0000</pubDate>
      <description><![CDATA[<p>Have you ever caught yourself thinking: ‚ÄúWhat am I even doing?‚Äù Well, that‚Äôs exactly how I feel right now. I was looking back at my previous tutorials and thought: ‚ÄúWhy not review them, critique them, and make a better version?‚Äù And here we are. In this first article, I‚Äôll revisit my initial tutorial: NUNit and C# - Tutorial to automate your API Tests from scratch .</p><p>I remember this project was born out of a real need at work. We had a lot of APIs with Postman tests, and we decided to migrate them to NUnit and C#. Now, looking back after over two years, I see many ways to improve it.</p><p>Starting from the tests that will be done. For this new project, we will use the https://dummyjson.com/ just to test some concepts, since the API are simple, and after that, we will refactor the tests for NASA API Tests. For the new endpoint we will automate the following tests:</p><p>The main goal is to make the project more robust, easier to replicate across scenarios, improve request handling, make it reusable for different projects, enable future CI/CD integration, and ensure sensitive data are protected.</p><p>The first major improvement is how we set up API requests. In my first article, I had a separate method for each API request. Now, I‚Äôve made them more abstract and maintainable:</p><p>And for the tests, they will be used in the following way:</p><p>Updating the NASA API tests, we will make two changes, first, move all the validations to a new class called CheckBodyResponse.cs:</p><p>And refactoring our tests, they will look like:</p><p>Improvements in This Version:</p><p>Setup notation: Makes tests cleaner and avoids repeating variables.</p><p>Abstract requests: One method for multiple endpoints instead of duplicating code.</p><p>Easier maintenance: The tests are more readable and modular.</p><p>Making the tests asyncronos.</p><p>Testing user data safely is always tricky. Here, we‚Äôll leverage Rider/Visual Studio‚Äôs .runsettings file:</p><p>.runsettings is an XML file that allows you to configure test parameters, environments, timeouts, and other TestRunner behaviors in Visual Studio or dotnet test.</p><p>.runsettings is an XML file that allows you to configure test parameters, environments, timeouts, and other TestRunner behaviors in Visual Studio or dotnet test.</p><p>‚ö†Ô∏è Do not commit this file to version control! Include it in .gitignore .</p><p>‚ö†Ô∏è Do not commit this file to version control! Include it in .gitignore .</p><p>We can then create a config class to handle local vs. CI environments:</p><p>This lets us run the same tests locally or in CI/CD pipelines seamlessly.</p><p>Read the rest of the article at the source.</p>]]></description>
      <content:encoded><![CDATA[<p>Have you ever caught yourself thinking: ‚ÄúWhat am I even doing?‚Äù Well, that‚Äôs exactly how I feel right now. I was looking back at my previous tutorials and thought: ‚ÄúWhy not review them, critique them, and make a better version?‚Äù And here we are. In this first article, I‚Äôll revisit my initial tutorial: NUNit and C# - Tutorial to automate your API Tests from scratch .</p><p>I remember this project was born out of a real need at work. We had a lot of APIs with Postman tests, and we decided to migrate them to NUnit and C#. Now, looking back after over two years, I see many ways to improve it.</p><p>Starting from the tests that will be done. For this new project, we will use the https://dummyjson.com/ just to test some concepts, since the API are simple, and after that, we will refactor the tests for NASA API Tests. For the new endpoint we will automate the following tests:</p><p>The main goal is to make the project more robust, easier to replicate across scenarios, improve request handling, make it reusable for different projects, enable future CI/CD integration, and ensure sensitive data are protected.</p><p>The first major improvement is how we set up API requests. In my first article, I had a separate method for each API request. Now, I‚Äôve made them more abstract and maintainable:</p><p>And for the tests, they will be used in the following way:</p><p>Updating the NASA API tests, we will make two changes, first, move all the validations to a new class called CheckBodyResponse.cs:</p><p>And refactoring our tests, they will look like:</p><p>Improvements in This Version:</p><p>Setup notation: Makes tests cleaner and avoids repeating variables.</p><p>Abstract requests: One method for multiple endpoints instead of duplicating code.</p><p>Easier maintenance: The tests are more readable and modular.</p><p>Making the tests asyncronos.</p><p>Testing user data safely is always tricky. Here, we‚Äôll leverage Rider/Visual Studio‚Äôs .runsettings file:</p><p>.runsettings is an XML file that allows you to configure test parameters, environments, timeouts, and other TestRunner behaviors in Visual Studio or dotnet test.</p><p>.runsettings is an XML file that allows you to configure test parameters, environments, timeouts, and other TestRunner behaviors in Visual Studio or dotnet test.</p><p>‚ö†Ô∏è Do not commit this file to version control! Include it in .gitignore .</p><p>‚ö†Ô∏è Do not commit this file to version control! Include it in .gitignore .</p><p>We can then create a config class to handle local vs. CI environments:</p><p>This lets us run the same tests locally or in CI/CD pipelines seamlessly.</p><p>Read the rest of the article at the source.</p>]]></content:encoded>
    </item>
    <item>
      <title>Stack Overflow: Time for a Change?</title>
      <link>https://dev.to/richardpascoe/stack-overflow-time-for-a-change-c2p</link>
      <guid isPermaLink="true">https://dev.to/richardpascoe/stack-overflow-time-for-a-change-c2p</guid>
      <pubDate>Tue, 10 Feb 2026 09:00:47 +0000</pubDate>
      <description><![CDATA[<p>Author‚Äôs note: I held this post back for a couple of weeks after some excellent subject-adjacent articles from @ingosteinke and @dannwaneri . I am publishing it now as a complementary perspective - hopefully a helpful one.</p><p>We&#x27;ve all been there - frantically searching Stack Overflow for that one solution, only to find the same question answered a dozen times, sometimes with cryptic or harsh comments. Stack Overflow has been a lifesaver for years, but let&#x27;s be honest: it&#x27;s not always the friendliest place to ask questions.</p><p>Lately, I&#x27;ve noticed more developers turning to other communities, like DEV, Hashnode, or smaller coding groups. These spaces feel more like talking to real people who get it - where you can ask questions, share your projects, and actually have a conversation.</p><p>There&#x27;s data backing this shift too. Stack Overflow&#x27;s own annual developer surveys have shown a steady drop in question engagement in recent years, while more developers report relying on AI tools like ChatGPT for quick answers instead of posting questions. As instant, conversational help becomes the norm, traditional Q&amp;A formats seem to be losing some of their pull.</p><p>In hindsight, it feels like Stack Overflow may have missed an opportunity to evolve alongside this shift. Instead of leaning harder into moderation and rigid Q&amp;A formats, it could have experimented more with conversational answers, beginner-friendly spaces, or even first-class AI assistance that still rewarded human expertise. The knowledge is there - the challenge has always been making the platform feel welcoming and adaptable to the people trying to contribute it.</p><p>So here&#x27;s the real question: do we need to replace Stack Overflow, or just expand the way we look for answers? Maybe the future of dev Q&amp;A isn&#x27;t one site, but a mix of communities that actually feel alive.</p><p>What about you - still loyal to Stack Overflow, or exploring new spaces?</p>]]></description>
      <content:encoded><![CDATA[<p>Author‚Äôs note: I held this post back for a couple of weeks after some excellent subject-adjacent articles from @ingosteinke and @dannwaneri . I am publishing it now as a complementary perspective - hopefully a helpful one.</p><p>We&#x27;ve all been there - frantically searching Stack Overflow for that one solution, only to find the same question answered a dozen times, sometimes with cryptic or harsh comments. Stack Overflow has been a lifesaver for years, but let&#x27;s be honest: it&#x27;s not always the friendliest place to ask questions.</p><p>Lately, I&#x27;ve noticed more developers turning to other communities, like DEV, Hashnode, or smaller coding groups. These spaces feel more like talking to real people who get it - where you can ask questions, share your projects, and actually have a conversation.</p><p>There&#x27;s data backing this shift too. Stack Overflow&#x27;s own annual developer surveys have shown a steady drop in question engagement in recent years, while more developers report relying on AI tools like ChatGPT for quick answers instead of posting questions. As instant, conversational help becomes the norm, traditional Q&amp;A formats seem to be losing some of their pull.</p><p>In hindsight, it feels like Stack Overflow may have missed an opportunity to evolve alongside this shift. Instead of leaning harder into moderation and rigid Q&amp;A formats, it could have experimented more with conversational answers, beginner-friendly spaces, or even first-class AI assistance that still rewarded human expertise. The knowledge is there - the challenge has always been making the platform feel welcoming and adaptable to the people trying to contribute it.</p><p>So here&#x27;s the real question: do we need to replace Stack Overflow, or just expand the way we look for answers? Maybe the future of dev Q&amp;A isn&#x27;t one site, but a mix of communities that actually feel alive.</p><p>What about you - still loyal to Stack Overflow, or exploring new spaces?</p>]]></content:encoded>
    </item>
  </channel>
</rss>